[
["daten-explorieren.html", "Kapitel 6 Daten explorieren 6.1 Daten einlesen 6.2 Datenjudo (Daten aufbereiten)", " Kapitel 6 Daten explorieren Den Ablauf des Datenexplorierens kann man so darstellen: Zuerst müssen die Daten für die Analyse(software) verfügbar gemacht werden. Sprich, die Daten müssen eingelesen werden. Dann beginnt das eigentliche Explorieren; dieses kann man wiederum in drei Schritte einteilen, die keine Abfolge sind, sondern sich wild abwechseln können. Diese sind: Daten aufbereiten, Daten zusammenfassen und Daten visualisieren. Unter Daten aufbereiten im engeren Sinne ist gemeint, die Daten einer “Grundreinigung” zu unterziehen, dass sie für weitere Analysen in geeigneter Form sind. Daten zusammenfassen meint die deskriptive Statistik; Daten visualisieren ist das Erstellen von Diagrammen. Im Anschluss kann man die Daten modellieren. Ist das Explorieren von Daten auch nicht statistisch anspruchsvoll, so ist es trotzdem von großer Bedeutung und häufig recht zeitintensiv, vor allem das Daten aufbereiten. Eine Anekdote zur Relevanz der Exploration, die (so will es die Geschichte) mir an einer Bar nach einer einschlägigen Konferenz erzählt wurde (daher keine Quellenangebe, Sie verstehen…). Eine Computerwissenschaftlerin aus den USA (deutschen Ursprungs) hatte einen beeindruckenden “Track Record” an Siegen in Wettkämpfen der Datenanalyse. Tatsächlich hatte sie keine besonderen, raffinierten Modellierungstechniken eingesetzt; klassische Regression war ihre Methode der Wahl. Bei einem Wettkampf, bei dem es darum ging, Krebsfälle aus Krankendaten vorherzusagen (z.B. Röntgenbildern) fand sie nach langem Datenjudo heraus, dass in die “ID-Variablen” Information gesickert war, die dort nicht hingehörte und die sie nutzen konnte für überraschend (aus Sicht der Mitstreiter) gute Vorhersagen zu Krebsfällen. Wie war das möglich? Die Daten stammten aus mehreren Kliniken, jede Klinik verwendete ein anderes System, um IDs für Patienten zu erstellen. Überall waren die IDs stark genug, um die Anonymität der Patienten sicherzustellen, aber gleich wohl konnte man (nach einigem Judo) unterscheiden, welche ID von welcher Klinik stammte. Was das bringt? Einige Kliniken waren reine Screening-Zentren, die die Normalbevölkerung versorgte. Dort sind wenig Krebsfälle zu erwarten. Andere Kliniken jedoch waren Onkologie-Zentren für bereits bekannte Patienten oder für Patienten mit besonderer Risikolage. Wenig überraschen, dass man dann höhere Krebsraten vorhersagen kann. Eigentlich ganz einfach; besondere Mathe steht hier (zumindest in dieser Geschichte) nicht dahinter. Und, wenn man den Trick kennt, ganz einfach. Aber wie so oft ist es nicht leicht, den Trick zu finden. Sorgfältiges Datenjudo hat hier den Schlüssel zum Erfolg gebracht. 6.1 Daten einlesen In R kann man ohne Weiteres verschiedene, gebräuchliche (Excel) oder weniger gebräuchliche (Feather) Datenformate einlesen. In RStudio lässt sich dies z.B. durch einen schnellen Klick auf Import Dataset im Reiter Environment erledigen. Dabei wird im Hintergrund das Paket readr verwendet (???) (die entsprechende Syntax wird in der Konsole ausgegeben, so dass man sie sich anschauen und weiterverwenden kann). Es ist für bestimmte Zwecke sinnvoll, nicht zu klicken, sondern die Syntax einzutippen. Zum Beispiel: Wenn Sie die komplette Analyse als Syntax in einer Datei haben (eine sog. “Skriptdatei”), dann brauchen Sie (in RStudio) nur alles auszuwählen und auf Run zu klicken, und die komplette Analyse läuft durch! Die Erfahrung zeigt, dass das ein praktisches Vorgehen ist. Die gebräuchlichste Form von Daten für statistische Analysen ist wahrscheinlich das CSV-Format. Das ist ein einfahes Format, basierend auf einer Textdatei. Schauen Sie sich mal diesen Auszug aus einer CSV-Datei an. &quot;ID&quot;,&quot;time&quot;,&quot;sex&quot;,&quot;height&quot;,&quot;shoe_size&quot; &quot;1&quot;,&quot;04.10.2016 17:58:51&quot;,NA,160.1,40 &quot;2&quot;,&quot;04.10.2016 17:58:59&quot;,&quot;woman&quot;,171.2,39 &quot;3&quot;,&quot;04.10.2016 18:00:15&quot;,&quot;woman&quot;,174.2,39 &quot;4&quot;,&quot;04.10.2016 18:01:17&quot;,&quot;woman&quot;,176.4,40 &quot;5&quot;,&quot;04.10.2016 18:01:22&quot;,&quot;man&quot;,195.2,46 Erkenenn Sie das Muster? Die erste Zeile gibt die “Spaltenköpfe” wieder, also die Namen der Variablen. Hier sind es 5 Spalten; die vierte heißt “shoe_size”. Die Spalten sind offenbar durch Komma , voneinander getrennt. Dezimalstellen sind in amerikanischer Manier mit einem Punkt . dargestellt. Die Daten sind “rechteckig”; alle Spalten haben gleich viele Zeilen und umgekehrt alle Spalten gleich viele Zeilen. Man kann sich diese Tabelle gut als Excel-Tabelle mit Zellen vorstellen, in denen z.B. “ID” (Zelle oben links) oder “46” (Zelle unten rechts) steht. An einer Stelle steht NA. Das ist Errisch für “fehlender Wert”. Häufig wird die Zelle auch leer gelassen, um auszudrücken, dass ein Wert hier fehlt (hört sich nicht ganz doof an). Aber man findet alle möglichen Ideen, um fehlende Werte darzustellen. Ich rate von allen anderen ab; führt nur zu Verwirrung. Lesen wir diese Daten jetzt ein: daten &lt;- read.csv(&quot;https://sebastiansauer.github.io/data/wo_men.csv&quot;) head(daten) #&gt; time sex height shoe_size #&gt; 1 04.10.2016 17:58:51 woman 160 40 #&gt; 2 04.10.2016 17:58:59 woman 171 39 #&gt; 3 04.10.2016 18:00:15 woman 174 39 #&gt; 4 04.10.2016 18:01:17 woman 176 40 #&gt; 5 04.10.2016 18:01:22 man 195 46 #&gt; 6 04.10.2016 18:01:53 woman 157 37 Der Befehl read.csv liest eine CSV-Datei, was uns jetzt nicht übermäßig überrascht. Aber Achtung: Wenn Sie aus einem Excel mit deutscher Einstellung eine CSV-Datei exportieren, wird diese CSV-Datei als Trennzeichen ; (Strichpunkt) und als Dezimaltrennzeichen , verwenden. Da der Befehl read.csv als Standard mit Komma und Punkt arbeitet, müssen wir die deutschen Sonderlocken explizit angeben, z.B. so: # daten_deutsch &lt;- read.csv(&quot;daten_deutsch.csv&quot;, sep = &quot;;&quot;, dec = &quot;.&quot;) Dabei steht sep (separator) für das Trennzeichen zwischen den Spalten und dec für das Dezimaltrennzeichen. Übrigens: Wenn Sie keinen Pfad angeben, so geht R davon aus, dass die Daten im aktuellen Verzeichnis liegen. Das aktuelle Verzeichnis kann man mit getwd() erfragen und mit setwd() einstellen. Komfortabler ist es aber, das aktuelle Verzeichnis per Menü zu ändern. In RStudio: Session &gt; Set Working Directory &gt; Choose Directory ... (oder per Shortcut, der dort angezeigt wird). 6.2 Datenjudo (Daten aufbereiten) Bevor man seine Statistik-Trickkiste so richtig schön aufmachen kann, muss man die Daten häufig erst noch in Form bringen. Das ist nicht schwierig in dem Sinne, dass es um komplizierte Mathe ginge. Allerdings braucht es mitunter recht viel Zeit und ein paar (oder viele) handwerkliche Tricks sind hilfreich. Hier soll das folgende Kapitel helfen. Mit “Datenjudo” (ein Fachbegriff aus der östlichen Zahlentheorie) ist gemeint, die Daten so “umzuformen”, “aufzubereiten”, oder “reinigen” , dass sie passend für statistische Analysen sind. Typische Probleme, die immer wieder auftreten sind: Fehlende Werte: Irgend jemand hat auf eine meiner schönen Fragen in der Umfrage nicht geantwortet! Unerwartete Daten: Auf die Frage, wie viele Facebook-Freunde er oder sie habe, schrieb die Person “I like you a lot”. Was tun??? Daten müssen umgeformt werden: Für jede der beiden Gruppen seiner Studie hat Joachim einen Google-Forms-Fragebogen aufgesetzt. Jetzt hat er zwei Tabellen, die er “verheiraten” möchte. Geht das? Neue Spalten berechnen: Ein Student fragt nach der Anzahl der richtigen Aufgaben in der Statistik-Probeklausur. Wir wollen helfen und im entsprechenden Datensatz eine Spalte erzeugen, in der pro Person die Anzahl der richtig beantworteten Fragen steht. 6.2.1 Überblick 6.2.2 Normalform einer Tabelle Tabellen in R werden als data frames (oder moderner: als tibble, kurz für “Table-df”) bezeichnet. Tabellen sollten in “Normalform” vorliegen, bevor wir weitere Analysen starten. Unter Normalform verstehen sich folgende Punkte: Es handelt sich um einen data frame, also Spalten mit Namen und gleicher Länge; eine Datentabelle in rechteckiger Form In jeder Zeile steht eine Beobachtung, in jeder Spalte eine Variable Fehlende Werte sollten sich in leeren Tabellen niederschlagen Daten sollten nicht mit Farkbmarkierungen o.ä. kodiert werden keine Leerzeilen, keine Leerspalten am besten keine Sonderzeichen verwenden und keine Leerzeichen in Variablennamen und -werten, am besten nur Ziffern und Buchstaben und Unterstriche Variablennamen dürfen nicht mit einer Zahl beginnen Der Punkt “Jede Zeile eine Beobachtung, jede Spalte eine Variable” verdient besondere Beachtung. Betrachen Sie dieses Beispiel: knitr::include_graphics(&quot;./images/breit_lang.pdf&quot;) In der rechten Tabelle sind die Variablen Quartal und Umsatz klar getrennt; jede hat ihre eigene Spalte. In der linken Tabelle hingegen sind die beiden Variablen vermischt. Sie haben nicht mehr ihre eigene Spalte, sondern sind über vier Spalten verteilt. Die rechte Tabelle ist ein Beispiel für eine Tabelle in Normalform, die linke nicht. Eine der ersten Aktionen einer Datenanalyse sollte also die “Normalisierung” Ihrer Tabelle sein. In R bietet sich dazu das Paket tidyr an, mit dem die Tabelle von Breit- auf Langformat (und wieder zurück) geschoben werden kann. Ein Beispiel dazu: meindf &lt;- read.csv(&quot;http://stanford.edu/~ejdemyr/r-tutorials/data/unicef-u5mr.csv&quot;) df_lang &lt;- gather(meindf, year, u5mr, U5MR.1950:U5MR.2015) df_lang &lt;- separate(df_lang, year, into = c(&quot;U5MR&quot;, &quot;year&quot;), sep = &quot;.&quot;) Die erste Zeile liest die Daten aus einer CSV-Datei ein; praktischerweise direkt von einer Webseite. Die zweite Zeile formt die Daten von breit nach lang um. Die neuen Spalten, nach der Umformung heißen dann year und u5mr (Sterblichkeit bei Kindern unter fünf Jahren). In die Umformung werden die Spalten U5MR 1950 bis U5MR 2015 einbezogen. Die dritte Zeile “entzerrt” die Werte der Spalte year; hier stehen die ehemaligen Spaltenköpfe. Man nennt sie auch key Spalte daher. Steht in einer Zelle von year bspw. U5MR 1950, so wird U5MR in eine Spalte mit Namen U5MR und 1950 in eine Spalte mit Namen year geschrieben. Im Cheatsheet von RStudio zum Thema Datenimport finden sich nützliche Hinweise [^3]. [^3]: https://www.rstudio.com/resources/cheatsheets/ 6.2.3 Daten aufbereiten mit dplyr Es gibt viele Möglichkeiten, Daten mit R aufzubereiten; dplyr ist ein populäres Paket dafür. Die Philosophie dabei ist, dass es ein paar wenige Grundbausteine geben sollte, die sich gut kombinieren lassen. Sprich: Wenige grundlegende Funktionen mit eng umgrenzter Funktionalität. Der Autor, Hadley Wickham, sprach einmal in einem Forum (citation needed), dass diese Befehle wenig können, das Wenige aber gut. Ein Nachteil dieser Konzeption kann sein, dass man recht viele dieser Bausteine kombinieren muss, um zum gewünschten Ergebnis zu kommen. Außerdem muss man die Logik des Baukastens gut verstanden habe - die Lernkurve ist also erstmal steiler. Dafür ist man dann nicht darauf angewiesen, dass es irgendwo “Mrs Right” gibt, die genau das kann, so wie ich das will. Außerdem braucht man sich auch nicht viele Funktionen merken. Es reicht einen kleinen Satz an Funktionen zu kennen (die praktischerweise konsistent in Syntax und Methodik sind). dplyr hat seinen Namen, weil es sich ausschließlich um Dataframes bemüht; es erwartet einen Dataframe als Eingabe und gibt einen Dataframe zurück1. Diese Bausteine sind typische Tätigkeiten im Umgang mit Daten; nichts Überraschendes. Schauen wir uns diese Bausteine näher an. library(dplyr) # muss installiert sein 6.2.3.1 Zeilen filtern mit filter Häufig will man bestimmte Zeilen aus einer Tabelle filtern. Zum Beispiel man arbeitet für die Zigarettenindustrie und ist nur an den Rauchern interessiert (die im Übrigen unser Gesundheitssystem retten (Krämer 2011)), nicht an Nicht-Rauchern; es sollen die nur Umsatzzahlen des letzten Quartals untersucht werden, nicht die vorherigen Quartale; es sollen nur die Daten aus Labor X (nicht Labor Y) ausgewertet werden etc. Ein Sinnbild: Merke: &gt; Die Funktion filter filtert Zeilen aus einem Dataframe. Schauen wir uns einige Beispiel an; zuerst die Daten laden nicht vergessen. Achtung: “Wohnen” die Daten in einem Paket, muss dieses Paket installiert sein, damit man auf die Daten zugreifen kann. data(profiles, package = &quot;okcupiddata&quot;) # Das Paket muss installiert sein df_frauen &lt;- filter(profiles, sex == &quot;f&quot;) # nur die Frauen df_alt &lt;- filter(profiles, age &gt; 70) # nur die alten df_alte_frauen &lt;- filter(profiles, age &gt; 70, sex == &quot;f&quot;) # nur die alten Frauen, d.h. UND-Verknüpfung df_nosmoke_nodrinks &lt;- filter(profiles, smokes == &quot;no&quot; | drinks == &quot;not at all&quot;) # liefert alle Personen, die Nicht-Raucher *oder* Nicht-Trinker sind Gar nicht so schwer, oder? Allgemeiner gesprochen werden diejenigen Zeilen gefiltert (also behalten bzw. zurückgeliefert), für die das Filterkriterium TRUE ist. Manche Befehle wie filter haben einen Allerweltsnamen; gut möglich, dass ein Befehl mit gleichem Namen in einem anderen (geladenen) Paket existiert. Das kann dann zu Verwirrungen führen - und kryptischen Fehlern. Im Zweifel den Namen des richtigen Pakets ergänzen, und zwar zum Beispiel so: dplyr::filter(...). Einige fortgeschrittene Beispiele für filter: Man kann alle Elemente (Zeilen) filtern, die zu einer Menge gehören und zwar mit diesem Operator: %in%: filter(profiles, body_type %in% c(&quot;a little extra&quot;, &quot;average&quot;)) Besonders Textdaten laden zu einigen Extra-Überlegungen ein; sagen wir, wir wollen alle Personen filtern, die Katzen bei den Haustieren erwähnen. Es soll reichen, wenn cat ein Teil des Textes ist; also likes dogs and likes cats wäre OK (soll gefiltert werden). Dazu nutzen wir ein Paket zur Bearbeitung von Strings (Textdaten): library(stringr) # muss installiert sein filter(profiles, str_detect(pets, &quot;cats&quot;)) Ein häufiger Fall ist, Zeilen ohne fehlende Werte (NAs) zu filtern. Das geht einfach: profiles_keine_nas &lt;- na.omit(profiles) Aber was ist, wenn wir nur bei bestimmten Spalten wegen fehlender Werte besorgt sind? Sagen wir bei income und bei sex: filter(profiles, !is.na(income) | !is.na(sex)) 6.2.3.2 Spalten wählen mit select Das Gegenstück zu filter ist select; dieser Befehl liefert die gewählten Spalten zurück. Das ist häufig praktisch, wenn der Datensatz sehr “breit” ist, also viele Spalten enthält. Dann kann es übersichtlicher sein, sich nur die relevanten auszuwählen. Das Sinnbild für diesen Befehl: Merke: Die Funktion select wählt Spalten aus einem Dataframe aus. if (!file.exists(&quot;./data/test_inf_short.csv&quot;)) { stats_test &lt;- read.csv(&quot;https://sebastiansauer.github.io/data/test_inf_short.csv&quot;) } else { stats_test &lt;- read.csv(&quot;./data/test_inf_short.csv&quot;) } Hier haben wir erst geprüft, ob die Datei test_inf_short.csv existiert; falls nein, laden wir sie herunter. Andernfalls lesen wir sie aus dem lokalen Verzeichnis. select(stats_test, score) # Spalte `score` auswählen select(stats_test, score, study_time) # Splaten `score` und `study_time` auswählen select(stats_test, score:study_time) # dito select(stats_test, 5:6) Spalten 5 bis 6 auswählen Tatsächlich ist der Befehl select sehr flexibel; es gibt viele Möglichkeiten, Spalten auszuwählen. Im dplyr-Cheatsheet findet sich ein guter Überblick dazu2. 6.2.3.3 Zeilen sortieren mit arrange Man kann zwei Arten des Umgangs mit R unterscheiden: Zum einen der “interaktive Gebrauch” und zum anderen “richtiges Programmieren”. Im interaktiven Gebrauch geht es uns darum, die Fragen zum aktuell vorliegenden Datensatz (schnell) zu beantworten. Es geht nicht darum, eine allgemeine Lösung zu entwickeln, die wir in die Welt verschicken können und die dort ein bestimmtes Problem löst, ohne dass der Entwickler (wir) dabei Hilfestellung geben muss. “Richtige” Software, wie ein R-Paket oder Microsoft Powerpoint, muss diese Erwartung erfüllen; “richtiges Programmieren” ist dazu vonnöten. Natürlich sind in diesem Fall die Ansprüche an die Syntax (der “Code”, hört sich cooler an) viel höher. In dem Fall muss man alle Eventualitäten voraussehen und sicherstellen, dass das Programm auch beim merkwürdigsten Nutzer brav seinen Dienst tut. Wir haben hier, beim interaktiven Gebrauch, niedrigere Ansprüche bzw. andere Ziele. Beim interaktiven Gebrauch von R (oder beliebigen Analyseprogrammen) ist das Sortieren von Zeilen eine recht häufige Tätigkeit. Typisches Beispiel wäre der Lehrer, der eine Tabelle mit Noten hat und wissen will, welche Schüler die schlechtesten oder die besten sind in einem bestimmten Fach. Oder bei der Prüfung der Umsätze nach Filialen möchten wir die umsatzstärksten sowie -schwächsten Niederlassungen kennen. Ein R-Befehl hierzu ist arrange; einige Beispiele zeigen die Funktionsweise am besten: arrange(stats_test, score) # liefert die *schlechtesten* Noten zurück #&gt; X V_1 study_time self_eval interest score #&gt; 1 234 23.01.2017 18:13:15 3 1 1 17 #&gt; 2 4 06.01.2017 09:58:05 2 3 2 18 #&gt; 3 131 19.01.2017 18:03:45 2 3 4 18 #&gt; 4 142 19.01.2017 19:02:12 3 4 1 18 #&gt; 5 35 12.01.2017 19:04:43 1 2 3 19 #&gt; 6 71 15.01.2017 15:03:29 3 3 3 20 #&gt; 7 97 17.01.2017 21:51:05 3 3 5 20 #&gt; 8 206 22.01.2017 18:42:49 NA NA NA 20 #&gt; 9 235 23.01.2017 18:26:20 NA NA NA 20 #&gt; 10 300 27.01.2017 02:14:27 2 3 2 20 #&gt; 11 33 12.01.2017 18:53:43 1 3 2 21 #&gt; 12 102 18.01.2017 12:48:04 3 3 3 21 #&gt; 13 129 19.01.2017 17:58:02 2 4 3 21 #&gt; 14 186 21.01.2017 16:24:44 2 5 3 21 #&gt; 15 216 23.01.2017 07:54:17 4 2 5 21 #&gt; 16 223 23.01.2017 12:53:02 3 1 3 21 #&gt; 17 13 09.01.2017 09:51:37 1 2 2 22 #&gt; 18 19 10.01.2017 17:16:48 NA NA NA 22 #&gt; 19 36 12.01.2017 19:09:14 1 7 3 22 #&gt; 20 55 14.01.2017 15:15:38 3 4 5 22 #&gt; 21 65 15.01.2017 12:41:27 3 6 6 22 #&gt; 22 220 23.01.2017 11:27:11 3 5 3 22 #&gt; 23 266 25.01.2017 15:39:13 2 4 4 22 #&gt; 24 269 25.01.2017 16:31:46 3 3 3 22 #&gt; 25 31 12.01.2017 14:09:10 4 8 5 23 #&gt; 26 45 13.01.2017 16:57:26 1 2 3 23 #&gt; 27 72 15.01.2017 15:30:15 4 4 4 23 #&gt; 28 86 16.01.2017 15:31:38 2 4 2 23 #&gt; 29 167 20.01.2017 19:17:44 4 5 4 23 #&gt; 30 195 22.01.2017 13:24:51 NA NA NA 23 #&gt; 31 221 23.01.2017 11:40:30 1 1 1 23 #&gt; 32 230 23.01.2017 16:27:49 1 1 1 23 #&gt; 33 283 26.01.2017 10:39:44 NA NA NA 23 #&gt; 34 8 06.01.2017 17:24:53 2 5 3 24 #&gt; 35 16 09.01.2017 15:52:12 2 5 3 24 #&gt; 36 28 11.01.2017 22:44:23 2 6 2 24 #&gt; 37 30 12.01.2017 13:36:07 3 5 2 24 #&gt; 38 37 12.01.2017 19:20:25 3 3 4 24 #&gt; 39 67 15.01.2017 13:30:48 NA NA NA 24 #&gt; 40 92 17.01.2017 17:18:55 1 1 1 24 #&gt; 41 107 18.01.2017 16:01:36 3 2 1 24 #&gt; 42 130 19.01.2017 17:58:35 3 1 4 24 #&gt; 43 217 23.01.2017 11:18:51 2 6 3 24 #&gt; 44 232 23.01.2017 16:50:14 3 2 4 24 #&gt; 45 246 24.01.2017 15:09:44 NA NA NA 24 #&gt; 46 9 07.01.2017 10:11:17 2 3 5 25 #&gt; 47 25 11.01.2017 20:30:43 2 1 1 25 #&gt; 48 32 12.01.2017 18:47:45 1 5 3 25 #&gt; 49 51 14.01.2017 13:55:30 2 5 2 25 #&gt; 50 69 15.01.2017 14:10:13 3 6 5 25 #&gt; 51 123 19.01.2017 12:36:03 1 3 4 25 #&gt; 52 161 20.01.2017 18:00:00 2 1 1 25 #&gt; 53 164 20.01.2017 18:17:03 3 4 2 25 #&gt; 54 209 22.01.2017 19:39:51 4 4 4 25 #&gt; 55 295 26.01.2017 16:18:27 1 3 1 25 #&gt; 56 302 27.01.2017 08:44:41 1 5 1 25 #&gt; 57 20 10.01.2017 18:33:15 3 5 2 26 #&gt; 58 26 11.01.2017 20:38:16 1 3 1 26 #&gt; 59 50 14.01.2017 10:53:38 1 3 2 26 #&gt; 60 53 14.01.2017 15:04:05 1 2 3 26 #&gt; 61 54 14.01.2017 15:14:50 3 5 2 26 #&gt; 62 105 18.01.2017 15:46:15 3 6 4 26 #&gt; 63 112 18.01.2017 19:41:09 3 5 5 26 #&gt; 64 120 19.01.2017 10:17:15 3 7 4 26 #&gt; 65 140 19.01.2017 18:37:53 3 7 4 26 #&gt; 66 151 20.01.2017 11:27:08 2 4 1 26 #&gt; 67 187 21.01.2017 16:27:32 NA NA NA 26 #&gt; 68 205 22.01.2017 18:29:17 2 2 1 26 #&gt; 69 228 23.01.2017 14:53:46 3 5 4 26 #&gt; 70 256 25.01.2017 10:39:53 2 2 3 26 #&gt; 71 273 25.01.2017 17:11:34 3 4 3 26 #&gt; 72 66 15.01.2017 13:28:29 1 3 1 27 #&gt; 73 81 15.01.2017 20:59:54 3 3 4 27 #&gt; 74 95 17.01.2017 20:52:29 2 4 5 27 #&gt; 75 109 18.01.2017 17:47:57 2 4 5 27 #&gt; 76 154 20.01.2017 13:38:19 4 5 1 27 #&gt; 77 200 22.01.2017 16:21:18 2 5 4 27 #&gt; 78 203 22.01.2017 17:22:06 3 4 5 27 #&gt; 79 208 22.01.2017 18:58:58 1 2 2 27 #&gt; 80 222 23.01.2017 12:06:58 3 6 5 27 #&gt; 81 227 23.01.2017 14:30:40 3 8 3 27 #&gt; 82 236 23.01.2017 18:48:02 3 2 3 27 #&gt; 83 237 23.01.2017 19:07:33 3 2 3 27 #&gt; 84 238 23.01.2017 19:53:10 NA NA NA 27 #&gt; 85 243 24.01.2017 14:15:59 4 4 2 27 #&gt; 86 251 24.01.2017 20:02:38 1 1 2 27 #&gt; 87 24 11.01.2017 19:38:20 3 2 3 28 #&gt; 88 59 14.01.2017 16:26:40 2 6 3 28 #&gt; 89 61 14.01.2017 17:27:31 3 6 3 28 #&gt; 90 70 15.01.2017 15:01:12 3 4 2 28 #&gt; 91 80 15.01.2017 20:39:10 3 6 3 28 #&gt; 92 82 15.01.2017 21:05:53 3 2 5 28 #&gt; 93 98 17.01.2017 21:59:36 2 2 2 28 #&gt; 94 145 19.01.2017 19:29:43 4 5 3 28 #&gt; 95 147 19.01.2017 20:36:23 4 4 2 28 #&gt; 96 173 20.01.2017 21:13:25 2 3 3 28 #&gt; 97 190 22.01.2017 11:19:10 3 6 2 28 #&gt; 98 207 22.01.2017 18:56:56 NA NA NA 28 #&gt; 99 210 22.01.2017 19:45:33 3 5 3 28 #&gt; 100 215 22.01.2017 22:00:29 1 2 2 28 #&gt; 101 224 23.01.2017 12:57:00 2 4 1 28 #&gt; 102 239 23.01.2017 20:00:46 3 4 1 28 #&gt; 103 242 24.01.2017 14:09:33 NA NA NA 28 #&gt; 104 245 24.01.2017 14:56:24 NA NA NA 28 #&gt; 105 247 24.01.2017 15:37:27 NA NA NA 28 #&gt; 106 270 25.01.2017 16:35:41 NA NA NA 28 #&gt; 107 288 26.01.2017 13:36:14 NA NA NA 28 #&gt; 108 1 05.01.2017 13:57:01 5 8 5 29 #&gt; 109 2 05.01.2017 21:07:56 3 7 3 29 #&gt; 110 47 13.01.2017 20:52:32 1 4 4 29 #&gt; 111 73 15.01.2017 15:49:52 4 3 4 29 #&gt; 112 87 16.01.2017 16:51:20 3 7 2 29 #&gt; 113 91 17.01.2017 15:19:36 NA NA NA 29 #&gt; 114 127 19.01.2017 14:20:15 2 1 2 29 #&gt; 115 152 20.01.2017 13:02:50 2 4 2 29 #&gt; 116 176 20.01.2017 23:18:18 3 5 3 29 #&gt; 117 213 22.01.2017 21:47:06 NA NA NA 29 #&gt; 118 255 25.01.2017 10:05:00 NA NA NA 29 #&gt; 119 261 25.01.2017 12:13:25 2 5 1 29 #&gt; 120 262 25.01.2017 12:49:57 1 2 1 29 #&gt; 121 276 25.01.2017 18:54:30 3 6 1 29 #&gt; 122 277 25.01.2017 20:06:34 3 4 1 29 #&gt; 123 282 26.01.2017 10:19:49 5 8 5 29 #&gt; 124 287 26.01.2017 11:56:19 4 8 3 29 #&gt; 125 15 09.01.2017 15:23:15 NA NA NA 30 #&gt; 126 23 11.01.2017 14:17:26 3 4 3 30 #&gt; 127 27 11.01.2017 20:49:19 2 4 5 30 #&gt; 128 44 13.01.2017 14:39:57 1 6 2 30 #&gt; 129 48 13.01.2017 21:50:03 2 4 5 30 #&gt; 130 57 14.01.2017 15:39:12 2 6 2 30 #&gt; 131 74 15.01.2017 16:12:54 NA NA NA 30 #&gt; 132 101 18.01.2017 12:32:04 4 7 2 30 #&gt; 133 114 18.01.2017 22:20:33 1 4 3 30 #&gt; 134 125 19.01.2017 13:03:26 NA NA NA 30 #&gt; 135 149 20.01.2017 09:02:45 3 5 4 30 #&gt; 136 182 21.01.2017 11:29:16 3 2 2 30 #&gt; 137 192 22.01.2017 11:52:16 2 5 2 30 #&gt; 138 198 22.01.2017 15:07:48 3 7 3 30 #&gt; 139 219 23.01.2017 11:24:30 2 7 5 30 #&gt; 140 265 25.01.2017 13:14:00 NA NA NA 30 #&gt; 141 12 08.01.2017 19:17:20 4 7 4 31 #&gt; 142 60 14.01.2017 17:14:18 2 7 2 31 #&gt; 143 78 15.01.2017 18:31:00 3 6 4 31 #&gt; 144 121 19.01.2017 11:29:43 1 1 1 31 #&gt; 145 139 19.01.2017 18:35:56 NA NA NA 31 #&gt; 146 157 20.01.2017 17:34:48 NA NA NA 31 #&gt; 147 183 21.01.2017 12:20:37 NA NA NA 31 #&gt; 148 193 22.01.2017 12:17:32 4 5 4 31 #&gt; 149 194 22.01.2017 12:27:59 4 6 3 31 #&gt; 150 201 22.01.2017 17:03:55 3 6 4 31 #&gt; 151 204 22.01.2017 17:45:23 1 3 2 31 #&gt; 152 214 22.01.2017 21:57:36 2 6 6 31 #&gt; 153 229 23.01.2017 15:20:08 5 7 4 31 #&gt; 154 241 24.01.2017 10:28:57 3 4 4 31 #&gt; 155 260 25.01.2017 11:59:11 3 6 4 31 #&gt; 156 263 25.01.2017 13:04:33 3 8 5 31 #&gt; 157 280 26.01.2017 03:01:08 4 7 4 31 #&gt; 158 289 26.01.2017 14:19:14 NA NA NA 31 #&gt; 159 11 08.01.2017 12:56:43 1 2 4 32 #&gt; 160 18 09.01.2017 22:57:38 3 3 5 32 #&gt; 161 46 13.01.2017 18:34:25 3 7 2 32 #&gt; 162 52 14.01.2017 14:46:16 1 9 2 32 #&gt; 163 76 15.01.2017 18:00:15 3 7 4 32 #&gt; 164 77 15.01.2017 18:21:19 4 5 5 32 #&gt; 165 90 17.01.2017 14:34:13 3 7 2 32 #&gt; 166 100 18.01.2017 11:29:13 4 7 4 32 #&gt; 167 124 19.01.2017 12:51:10 NA NA NA 32 #&gt; 168 150 20.01.2017 09:53:47 NA NA NA 32 #&gt; 169 168 20.01.2017 20:04:38 1 1 1 32 #&gt; 170 178 20.01.2017 23:54:46 3 6 4 32 #&gt; 171 184 21.01.2017 14:20:14 2 4 4 32 #&gt; 172 212 22.01.2017 21:34:56 4 5 4 32 #&gt; 173 250 24.01.2017 18:56:35 3 6 3 32 #&gt; 174 304 27.01.2017 09:18:26 3 8 2 32 #&gt; 175 10 07.01.2017 18:10:05 4 5 5 33 #&gt; 176 17 09.01.2017 20:49:48 2 5 3 33 #&gt; 177 21 10.01.2017 21:17:52 4 7 2 33 #&gt; 178 63 15.01.2017 11:41:07 2 5 3 33 #&gt; 179 68 15.01.2017 13:46:04 2 5 2 33 #&gt; 180 118 19.01.2017 08:54:43 NA NA NA 33 #&gt; 181 156 20.01.2017 17:28:23 4 7 5 33 #&gt; 182 199 22.01.2017 15:26:55 3 5 3 33 #&gt; 183 233 23.01.2017 17:03:10 2 9 2 33 #&gt; 184 254 25.01.2017 09:33:37 3 7 3 33 #&gt; 185 267 25.01.2017 16:08:48 3 6 3 33 #&gt; 186 297 26.01.2017 19:07:14 3 6 1 33 #&gt; 187 301 27.01.2017 08:17:59 4 8 6 33 #&gt; 188 5 06.01.2017 14:13:08 4 8 6 34 #&gt; 189 85 16.01.2017 13:56:29 3 6 5 34 #&gt; 190 88 16.01.2017 19:03:39 2 7 4 34 #&gt; 191 89 16.01.2017 21:18:05 NA NA NA 34 #&gt; 192 94 17.01.2017 19:47:11 3 7 3 34 #&gt; 193 115 18.01.2017 23:00:36 4 5 5 34 #&gt; 194 122 19.01.2017 11:30:57 2 2 1 34 #&gt; 195 141 19.01.2017 18:44:32 NA NA NA 34 #&gt; 196 143 19.01.2017 19:15:36 3 6 2 34 #&gt; 197 159 20.01.2017 17:57:26 NA NA NA 34 #&gt; 198 160 20.01.2017 17:59:19 NA NA NA 34 #&gt; 199 166 20.01.2017 19:03:10 4 6 3 34 #&gt; 200 170 20.01.2017 20:09:15 2 1 3 34 #&gt; 201 172 20.01.2017 20:42:46 5 10 6 34 #&gt; 202 177 20.01.2017 23:37:45 4 7 5 34 #&gt; 203 218 23.01.2017 11:21:21 3 5 3 34 #&gt; 204 240 24.01.2017 10:19:25 3 6 3 34 #&gt; 205 259 25.01.2017 11:37:19 5 7 5 34 #&gt; 206 271 25.01.2017 16:53:17 NA NA NA 34 #&gt; 207 275 25.01.2017 18:06:36 NA NA NA 34 #&gt; 208 285 26.01.2017 10:54:41 NA NA NA 34 #&gt; 209 294 26.01.2017 15:51:56 NA NA NA 34 #&gt; 210 14 09.01.2017 12:15:48 4 9 3 35 #&gt; 211 38 13.01.2017 07:55:14 3 8 3 35 #&gt; 212 62 14.01.2017 17:52:29 2 8 2 35 #&gt; 213 75 15.01.2017 17:31:06 1 2 1 35 #&gt; 214 79 15.01.2017 19:54:00 3 4 3 35 #&gt; 215 84 16.01.2017 13:51:51 4 8 5 35 #&gt; 216 93 17.01.2017 19:28:51 3 7 2 35 #&gt; 217 103 18.01.2017 13:32:09 4 7 5 35 #&gt; 218 148 19.01.2017 21:19:10 4 2 3 35 #&gt; 219 162 20.01.2017 18:00:53 NA NA NA 35 #&gt; 220 174 20.01.2017 22:58:35 5 8 5 35 #&gt; 221 231 23.01.2017 16:32:32 1 1 1 35 #&gt; 222 244 24.01.2017 14:38:56 3 5 3 35 #&gt; 223 305 27.01.2017 09:52:59 3 8 2 35 #&gt; 224 43 13.01.2017 14:14:16 4 8 6 36 #&gt; 225 128 19.01.2017 14:29:41 3 6 3 36 #&gt; 226 158 20.01.2017 17:53:16 NA NA NA 36 #&gt; 227 163 20.01.2017 18:04:21 NA NA NA 36 #&gt; 228 165 20.01.2017 18:57:33 2 8 5 36 #&gt; 229 188 21.01.2017 19:01:18 4 8 4 36 #&gt; 230 191 22.01.2017 11:31:27 NA NA NA 36 #&gt; 231 202 22.01.2017 17:13:02 NA NA NA 36 #&gt; 232 226 23.01.2017 14:17:10 NA NA NA 36 #&gt; 233 272 25.01.2017 17:03:21 NA NA NA 36 #&gt; 234 278 25.01.2017 21:08:40 5 6 5 36 #&gt; 235 279 25.01.2017 23:19:16 4 8 4 36 #&gt; 236 284 26.01.2017 10:46:10 4 5 4 36 #&gt; 237 290 26.01.2017 14:34:23 NA NA NA 36 #&gt; 238 293 26.01.2017 15:17:47 NA NA NA 36 #&gt; 239 96 17.01.2017 20:55:48 4 7 5 37 #&gt; 240 99 18.01.2017 09:04:30 NA NA NA 37 #&gt; 241 110 18.01.2017 18:53:02 5 8 6 37 #&gt; 242 111 18.01.2017 19:24:49 NA NA NA 37 #&gt; 243 117 19.01.2017 08:06:05 NA NA NA 37 #&gt; 244 126 19.01.2017 13:42:49 2 8 4 37 #&gt; 245 146 19.01.2017 20:08:34 4 7 2 37 #&gt; 246 153 20.01.2017 13:03:25 3 7 3 37 #&gt; 247 169 20.01.2017 20:05:13 3 5 1 37 #&gt; 248 171 20.01.2017 20:29:52 4 9 5 37 #&gt; 249 189 21.01.2017 20:05:54 4 6 2 37 #&gt; 250 274 25.01.2017 17:38:36 NA NA NA 37 #&gt; 251 299 26.01.2017 23:10:18 5 4 2 37 #&gt; 252 22 11.01.2017 13:32:30 4 9 5 38 #&gt; 253 34 12.01.2017 18:57:47 4 7 1 38 #&gt; 254 42 13.01.2017 14:08:08 NA NA NA 38 #&gt; 255 106 18.01.2017 15:52:04 NA NA NA 38 #&gt; 256 113 18.01.2017 21:44:02 5 8 5 38 #&gt; 257 133 19.01.2017 18:22:38 NA NA NA 38 #&gt; 258 181 21.01.2017 08:26:17 4 9 5 38 #&gt; 259 211 22.01.2017 20:28:43 NA NA NA 38 #&gt; 260 252 25.01.2017 08:56:16 5 7 3 38 #&gt; 261 258 25.01.2017 11:25:38 5 9 5 38 #&gt; 262 268 25.01.2017 16:15:57 4 7 4 38 #&gt; 263 281 26.01.2017 10:13:05 4 7 4 38 #&gt; 264 286 26.01.2017 11:19:10 NA NA NA 38 #&gt; 265 296 26.01.2017 17:12:37 3 6 3 38 #&gt; 266 298 26.01.2017 20:41:21 2 5 3 38 #&gt; 267 303 27.01.2017 08:50:31 5 8 3 38 #&gt; 268 6 06.01.2017 14:21:18 NA NA NA 39 #&gt; 269 39 13.01.2017 08:54:17 3 10 3 39 #&gt; 270 40 13.01.2017 09:31:06 4 9 3 39 #&gt; 271 49 14.01.2017 07:02:39 NA NA NA 39 #&gt; 272 56 14.01.2017 15:27:10 3 8 2 39 #&gt; 273 64 15.01.2017 11:49:03 3 8 3 39 #&gt; 274 104 18.01.2017 13:42:20 NA NA NA 39 #&gt; 275 108 18.01.2017 16:38:36 5 8 5 39 #&gt; 276 134 19.01.2017 18:22:43 1 4 4 39 #&gt; 277 135 19.01.2017 18:22:55 3 3 4 39 #&gt; 278 136 19.01.2017 18:22:57 3 1 6 39 #&gt; 279 137 19.01.2017 18:22:58 4 10 5 39 #&gt; 280 138 19.01.2017 18:23:23 3 9 3 39 #&gt; 281 144 19.01.2017 19:23:57 4 8 3 39 #&gt; 282 155 20.01.2017 15:33:55 NA NA NA 39 #&gt; 283 180 21.01.2017 08:04:17 NA NA NA 39 #&gt; 284 225 23.01.2017 13:24:22 NA NA NA 39 #&gt; 285 253 25.01.2017 09:32:55 NA NA NA 39 #&gt; 286 264 25.01.2017 13:11:14 4 10 5 39 #&gt; 287 291 26.01.2017 14:55:17 NA NA NA 39 #&gt; 288 292 26.01.2017 15:00:29 4 8 3 39 #&gt; 289 3 05.01.2017 23:33:47 5 10 6 40 #&gt; 290 7 06.01.2017 14:25:49 NA NA NA 40 #&gt; 291 29 12.01.2017 09:48:16 4 10 3 40 #&gt; 292 41 13.01.2017 12:07:29 4 10 3 40 #&gt; 293 58 14.01.2017 15:43:01 3 8 2 40 #&gt; 294 83 16.01.2017 10:16:52 NA NA NA 40 #&gt; 295 116 18.01.2017 23:07:32 4 8 5 40 #&gt; 296 119 19.01.2017 09:05:01 NA NA NA 40 #&gt; 297 132 19.01.2017 18:22:32 NA NA NA 40 #&gt; 298 175 20.01.2017 23:03:36 5 10 5 40 #&gt; 299 179 21.01.2017 07:40:05 5 9 1 40 #&gt; 300 185 21.01.2017 15:01:26 4 10 5 40 #&gt; 301 196 22.01.2017 13:38:56 4 10 5 40 #&gt; 302 197 22.01.2017 14:55:17 4 10 5 40 #&gt; 303 248 24.01.2017 16:29:45 2 10 2 40 #&gt; 304 249 24.01.2017 17:19:54 NA NA NA 40 #&gt; 305 257 25.01.2017 10:44:34 2 9 3 40 #&gt; 306 306 27.01.2017 11:29:48 4 9 3 40 arrange(stats_test, -score) # liefert die *besten* Noten zurück #&gt; X V_1 study_time self_eval interest score #&gt; 1 3 05.01.2017 23:33:47 5 10 6 40 #&gt; 2 7 06.01.2017 14:25:49 NA NA NA 40 #&gt; 3 29 12.01.2017 09:48:16 4 10 3 40 #&gt; 4 41 13.01.2017 12:07:29 4 10 3 40 #&gt; 5 58 14.01.2017 15:43:01 3 8 2 40 #&gt; 6 83 16.01.2017 10:16:52 NA NA NA 40 #&gt; 7 116 18.01.2017 23:07:32 4 8 5 40 #&gt; 8 119 19.01.2017 09:05:01 NA NA NA 40 #&gt; 9 132 19.01.2017 18:22:32 NA NA NA 40 #&gt; 10 175 20.01.2017 23:03:36 5 10 5 40 #&gt; 11 179 21.01.2017 07:40:05 5 9 1 40 #&gt; 12 185 21.01.2017 15:01:26 4 10 5 40 #&gt; 13 196 22.01.2017 13:38:56 4 10 5 40 #&gt; 14 197 22.01.2017 14:55:17 4 10 5 40 #&gt; 15 248 24.01.2017 16:29:45 2 10 2 40 #&gt; 16 249 24.01.2017 17:19:54 NA NA NA 40 #&gt; 17 257 25.01.2017 10:44:34 2 9 3 40 #&gt; 18 306 27.01.2017 11:29:48 4 9 3 40 #&gt; 19 6 06.01.2017 14:21:18 NA NA NA 39 #&gt; 20 39 13.01.2017 08:54:17 3 10 3 39 #&gt; 21 40 13.01.2017 09:31:06 4 9 3 39 #&gt; 22 49 14.01.2017 07:02:39 NA NA NA 39 #&gt; 23 56 14.01.2017 15:27:10 3 8 2 39 #&gt; 24 64 15.01.2017 11:49:03 3 8 3 39 #&gt; 25 104 18.01.2017 13:42:20 NA NA NA 39 #&gt; 26 108 18.01.2017 16:38:36 5 8 5 39 #&gt; 27 134 19.01.2017 18:22:43 1 4 4 39 #&gt; 28 135 19.01.2017 18:22:55 3 3 4 39 #&gt; 29 136 19.01.2017 18:22:57 3 1 6 39 #&gt; 30 137 19.01.2017 18:22:58 4 10 5 39 #&gt; 31 138 19.01.2017 18:23:23 3 9 3 39 #&gt; 32 144 19.01.2017 19:23:57 4 8 3 39 #&gt; 33 155 20.01.2017 15:33:55 NA NA NA 39 #&gt; 34 180 21.01.2017 08:04:17 NA NA NA 39 #&gt; 35 225 23.01.2017 13:24:22 NA NA NA 39 #&gt; 36 253 25.01.2017 09:32:55 NA NA NA 39 #&gt; 37 264 25.01.2017 13:11:14 4 10 5 39 #&gt; 38 291 26.01.2017 14:55:17 NA NA NA 39 #&gt; 39 292 26.01.2017 15:00:29 4 8 3 39 #&gt; 40 22 11.01.2017 13:32:30 4 9 5 38 #&gt; 41 34 12.01.2017 18:57:47 4 7 1 38 #&gt; 42 42 13.01.2017 14:08:08 NA NA NA 38 #&gt; 43 106 18.01.2017 15:52:04 NA NA NA 38 #&gt; 44 113 18.01.2017 21:44:02 5 8 5 38 #&gt; 45 133 19.01.2017 18:22:38 NA NA NA 38 #&gt; 46 181 21.01.2017 08:26:17 4 9 5 38 #&gt; 47 211 22.01.2017 20:28:43 NA NA NA 38 #&gt; 48 252 25.01.2017 08:56:16 5 7 3 38 #&gt; 49 258 25.01.2017 11:25:38 5 9 5 38 #&gt; 50 268 25.01.2017 16:15:57 4 7 4 38 #&gt; 51 281 26.01.2017 10:13:05 4 7 4 38 #&gt; 52 286 26.01.2017 11:19:10 NA NA NA 38 #&gt; 53 296 26.01.2017 17:12:37 3 6 3 38 #&gt; 54 298 26.01.2017 20:41:21 2 5 3 38 #&gt; 55 303 27.01.2017 08:50:31 5 8 3 38 #&gt; 56 96 17.01.2017 20:55:48 4 7 5 37 #&gt; 57 99 18.01.2017 09:04:30 NA NA NA 37 #&gt; 58 110 18.01.2017 18:53:02 5 8 6 37 #&gt; 59 111 18.01.2017 19:24:49 NA NA NA 37 #&gt; 60 117 19.01.2017 08:06:05 NA NA NA 37 #&gt; 61 126 19.01.2017 13:42:49 2 8 4 37 #&gt; 62 146 19.01.2017 20:08:34 4 7 2 37 #&gt; 63 153 20.01.2017 13:03:25 3 7 3 37 #&gt; 64 169 20.01.2017 20:05:13 3 5 1 37 #&gt; 65 171 20.01.2017 20:29:52 4 9 5 37 #&gt; 66 189 21.01.2017 20:05:54 4 6 2 37 #&gt; 67 274 25.01.2017 17:38:36 NA NA NA 37 #&gt; 68 299 26.01.2017 23:10:18 5 4 2 37 #&gt; 69 43 13.01.2017 14:14:16 4 8 6 36 #&gt; 70 128 19.01.2017 14:29:41 3 6 3 36 #&gt; 71 158 20.01.2017 17:53:16 NA NA NA 36 #&gt; 72 163 20.01.2017 18:04:21 NA NA NA 36 #&gt; 73 165 20.01.2017 18:57:33 2 8 5 36 #&gt; 74 188 21.01.2017 19:01:18 4 8 4 36 #&gt; 75 191 22.01.2017 11:31:27 NA NA NA 36 #&gt; 76 202 22.01.2017 17:13:02 NA NA NA 36 #&gt; 77 226 23.01.2017 14:17:10 NA NA NA 36 #&gt; 78 272 25.01.2017 17:03:21 NA NA NA 36 #&gt; 79 278 25.01.2017 21:08:40 5 6 5 36 #&gt; 80 279 25.01.2017 23:19:16 4 8 4 36 #&gt; 81 284 26.01.2017 10:46:10 4 5 4 36 #&gt; 82 290 26.01.2017 14:34:23 NA NA NA 36 #&gt; 83 293 26.01.2017 15:17:47 NA NA NA 36 #&gt; 84 14 09.01.2017 12:15:48 4 9 3 35 #&gt; 85 38 13.01.2017 07:55:14 3 8 3 35 #&gt; 86 62 14.01.2017 17:52:29 2 8 2 35 #&gt; 87 75 15.01.2017 17:31:06 1 2 1 35 #&gt; 88 79 15.01.2017 19:54:00 3 4 3 35 #&gt; 89 84 16.01.2017 13:51:51 4 8 5 35 #&gt; 90 93 17.01.2017 19:28:51 3 7 2 35 #&gt; 91 103 18.01.2017 13:32:09 4 7 5 35 #&gt; 92 148 19.01.2017 21:19:10 4 2 3 35 #&gt; 93 162 20.01.2017 18:00:53 NA NA NA 35 #&gt; 94 174 20.01.2017 22:58:35 5 8 5 35 #&gt; 95 231 23.01.2017 16:32:32 1 1 1 35 #&gt; 96 244 24.01.2017 14:38:56 3 5 3 35 #&gt; 97 305 27.01.2017 09:52:59 3 8 2 35 #&gt; 98 5 06.01.2017 14:13:08 4 8 6 34 #&gt; 99 85 16.01.2017 13:56:29 3 6 5 34 #&gt; 100 88 16.01.2017 19:03:39 2 7 4 34 #&gt; 101 89 16.01.2017 21:18:05 NA NA NA 34 #&gt; 102 94 17.01.2017 19:47:11 3 7 3 34 #&gt; 103 115 18.01.2017 23:00:36 4 5 5 34 #&gt; 104 122 19.01.2017 11:30:57 2 2 1 34 #&gt; 105 141 19.01.2017 18:44:32 NA NA NA 34 #&gt; 106 143 19.01.2017 19:15:36 3 6 2 34 #&gt; 107 159 20.01.2017 17:57:26 NA NA NA 34 #&gt; 108 160 20.01.2017 17:59:19 NA NA NA 34 #&gt; 109 166 20.01.2017 19:03:10 4 6 3 34 #&gt; 110 170 20.01.2017 20:09:15 2 1 3 34 #&gt; 111 172 20.01.2017 20:42:46 5 10 6 34 #&gt; 112 177 20.01.2017 23:37:45 4 7 5 34 #&gt; 113 218 23.01.2017 11:21:21 3 5 3 34 #&gt; 114 240 24.01.2017 10:19:25 3 6 3 34 #&gt; 115 259 25.01.2017 11:37:19 5 7 5 34 #&gt; 116 271 25.01.2017 16:53:17 NA NA NA 34 #&gt; 117 275 25.01.2017 18:06:36 NA NA NA 34 #&gt; 118 285 26.01.2017 10:54:41 NA NA NA 34 #&gt; 119 294 26.01.2017 15:51:56 NA NA NA 34 #&gt; 120 10 07.01.2017 18:10:05 4 5 5 33 #&gt; 121 17 09.01.2017 20:49:48 2 5 3 33 #&gt; 122 21 10.01.2017 21:17:52 4 7 2 33 #&gt; 123 63 15.01.2017 11:41:07 2 5 3 33 #&gt; 124 68 15.01.2017 13:46:04 2 5 2 33 #&gt; 125 118 19.01.2017 08:54:43 NA NA NA 33 #&gt; 126 156 20.01.2017 17:28:23 4 7 5 33 #&gt; 127 199 22.01.2017 15:26:55 3 5 3 33 #&gt; 128 233 23.01.2017 17:03:10 2 9 2 33 #&gt; 129 254 25.01.2017 09:33:37 3 7 3 33 #&gt; 130 267 25.01.2017 16:08:48 3 6 3 33 #&gt; 131 297 26.01.2017 19:07:14 3 6 1 33 #&gt; 132 301 27.01.2017 08:17:59 4 8 6 33 #&gt; 133 11 08.01.2017 12:56:43 1 2 4 32 #&gt; 134 18 09.01.2017 22:57:38 3 3 5 32 #&gt; 135 46 13.01.2017 18:34:25 3 7 2 32 #&gt; 136 52 14.01.2017 14:46:16 1 9 2 32 #&gt; 137 76 15.01.2017 18:00:15 3 7 4 32 #&gt; 138 77 15.01.2017 18:21:19 4 5 5 32 #&gt; 139 90 17.01.2017 14:34:13 3 7 2 32 #&gt; 140 100 18.01.2017 11:29:13 4 7 4 32 #&gt; 141 124 19.01.2017 12:51:10 NA NA NA 32 #&gt; 142 150 20.01.2017 09:53:47 NA NA NA 32 #&gt; 143 168 20.01.2017 20:04:38 1 1 1 32 #&gt; 144 178 20.01.2017 23:54:46 3 6 4 32 #&gt; 145 184 21.01.2017 14:20:14 2 4 4 32 #&gt; 146 212 22.01.2017 21:34:56 4 5 4 32 #&gt; 147 250 24.01.2017 18:56:35 3 6 3 32 #&gt; 148 304 27.01.2017 09:18:26 3 8 2 32 #&gt; 149 12 08.01.2017 19:17:20 4 7 4 31 #&gt; 150 60 14.01.2017 17:14:18 2 7 2 31 #&gt; 151 78 15.01.2017 18:31:00 3 6 4 31 #&gt; 152 121 19.01.2017 11:29:43 1 1 1 31 #&gt; 153 139 19.01.2017 18:35:56 NA NA NA 31 #&gt; 154 157 20.01.2017 17:34:48 NA NA NA 31 #&gt; 155 183 21.01.2017 12:20:37 NA NA NA 31 #&gt; 156 193 22.01.2017 12:17:32 4 5 4 31 #&gt; 157 194 22.01.2017 12:27:59 4 6 3 31 #&gt; 158 201 22.01.2017 17:03:55 3 6 4 31 #&gt; 159 204 22.01.2017 17:45:23 1 3 2 31 #&gt; 160 214 22.01.2017 21:57:36 2 6 6 31 #&gt; 161 229 23.01.2017 15:20:08 5 7 4 31 #&gt; 162 241 24.01.2017 10:28:57 3 4 4 31 #&gt; 163 260 25.01.2017 11:59:11 3 6 4 31 #&gt; 164 263 25.01.2017 13:04:33 3 8 5 31 #&gt; 165 280 26.01.2017 03:01:08 4 7 4 31 #&gt; 166 289 26.01.2017 14:19:14 NA NA NA 31 #&gt; 167 15 09.01.2017 15:23:15 NA NA NA 30 #&gt; 168 23 11.01.2017 14:17:26 3 4 3 30 #&gt; 169 27 11.01.2017 20:49:19 2 4 5 30 #&gt; 170 44 13.01.2017 14:39:57 1 6 2 30 #&gt; 171 48 13.01.2017 21:50:03 2 4 5 30 #&gt; 172 57 14.01.2017 15:39:12 2 6 2 30 #&gt; 173 74 15.01.2017 16:12:54 NA NA NA 30 #&gt; 174 101 18.01.2017 12:32:04 4 7 2 30 #&gt; 175 114 18.01.2017 22:20:33 1 4 3 30 #&gt; 176 125 19.01.2017 13:03:26 NA NA NA 30 #&gt; 177 149 20.01.2017 09:02:45 3 5 4 30 #&gt; 178 182 21.01.2017 11:29:16 3 2 2 30 #&gt; 179 192 22.01.2017 11:52:16 2 5 2 30 #&gt; 180 198 22.01.2017 15:07:48 3 7 3 30 #&gt; 181 219 23.01.2017 11:24:30 2 7 5 30 #&gt; 182 265 25.01.2017 13:14:00 NA NA NA 30 #&gt; 183 1 05.01.2017 13:57:01 5 8 5 29 #&gt; 184 2 05.01.2017 21:07:56 3 7 3 29 #&gt; 185 47 13.01.2017 20:52:32 1 4 4 29 #&gt; 186 73 15.01.2017 15:49:52 4 3 4 29 #&gt; 187 87 16.01.2017 16:51:20 3 7 2 29 #&gt; 188 91 17.01.2017 15:19:36 NA NA NA 29 #&gt; 189 127 19.01.2017 14:20:15 2 1 2 29 #&gt; 190 152 20.01.2017 13:02:50 2 4 2 29 #&gt; 191 176 20.01.2017 23:18:18 3 5 3 29 #&gt; 192 213 22.01.2017 21:47:06 NA NA NA 29 #&gt; 193 255 25.01.2017 10:05:00 NA NA NA 29 #&gt; 194 261 25.01.2017 12:13:25 2 5 1 29 #&gt; 195 262 25.01.2017 12:49:57 1 2 1 29 #&gt; 196 276 25.01.2017 18:54:30 3 6 1 29 #&gt; 197 277 25.01.2017 20:06:34 3 4 1 29 #&gt; 198 282 26.01.2017 10:19:49 5 8 5 29 #&gt; 199 287 26.01.2017 11:56:19 4 8 3 29 #&gt; 200 24 11.01.2017 19:38:20 3 2 3 28 #&gt; 201 59 14.01.2017 16:26:40 2 6 3 28 #&gt; 202 61 14.01.2017 17:27:31 3 6 3 28 #&gt; 203 70 15.01.2017 15:01:12 3 4 2 28 #&gt; 204 80 15.01.2017 20:39:10 3 6 3 28 #&gt; 205 82 15.01.2017 21:05:53 3 2 5 28 #&gt; 206 98 17.01.2017 21:59:36 2 2 2 28 #&gt; 207 145 19.01.2017 19:29:43 4 5 3 28 #&gt; 208 147 19.01.2017 20:36:23 4 4 2 28 #&gt; 209 173 20.01.2017 21:13:25 2 3 3 28 #&gt; 210 190 22.01.2017 11:19:10 3 6 2 28 #&gt; 211 207 22.01.2017 18:56:56 NA NA NA 28 #&gt; 212 210 22.01.2017 19:45:33 3 5 3 28 #&gt; 213 215 22.01.2017 22:00:29 1 2 2 28 #&gt; 214 224 23.01.2017 12:57:00 2 4 1 28 #&gt; 215 239 23.01.2017 20:00:46 3 4 1 28 #&gt; 216 242 24.01.2017 14:09:33 NA NA NA 28 #&gt; 217 245 24.01.2017 14:56:24 NA NA NA 28 #&gt; 218 247 24.01.2017 15:37:27 NA NA NA 28 #&gt; 219 270 25.01.2017 16:35:41 NA NA NA 28 #&gt; 220 288 26.01.2017 13:36:14 NA NA NA 28 #&gt; 221 66 15.01.2017 13:28:29 1 3 1 27 #&gt; 222 81 15.01.2017 20:59:54 3 3 4 27 #&gt; 223 95 17.01.2017 20:52:29 2 4 5 27 #&gt; 224 109 18.01.2017 17:47:57 2 4 5 27 #&gt; 225 154 20.01.2017 13:38:19 4 5 1 27 #&gt; 226 200 22.01.2017 16:21:18 2 5 4 27 #&gt; 227 203 22.01.2017 17:22:06 3 4 5 27 #&gt; 228 208 22.01.2017 18:58:58 1 2 2 27 #&gt; 229 222 23.01.2017 12:06:58 3 6 5 27 #&gt; 230 227 23.01.2017 14:30:40 3 8 3 27 #&gt; 231 236 23.01.2017 18:48:02 3 2 3 27 #&gt; 232 237 23.01.2017 19:07:33 3 2 3 27 #&gt; 233 238 23.01.2017 19:53:10 NA NA NA 27 #&gt; 234 243 24.01.2017 14:15:59 4 4 2 27 #&gt; 235 251 24.01.2017 20:02:38 1 1 2 27 #&gt; 236 20 10.01.2017 18:33:15 3 5 2 26 #&gt; 237 26 11.01.2017 20:38:16 1 3 1 26 #&gt; 238 50 14.01.2017 10:53:38 1 3 2 26 #&gt; 239 53 14.01.2017 15:04:05 1 2 3 26 #&gt; 240 54 14.01.2017 15:14:50 3 5 2 26 #&gt; 241 105 18.01.2017 15:46:15 3 6 4 26 #&gt; 242 112 18.01.2017 19:41:09 3 5 5 26 #&gt; 243 120 19.01.2017 10:17:15 3 7 4 26 #&gt; 244 140 19.01.2017 18:37:53 3 7 4 26 #&gt; 245 151 20.01.2017 11:27:08 2 4 1 26 #&gt; 246 187 21.01.2017 16:27:32 NA NA NA 26 #&gt; 247 205 22.01.2017 18:29:17 2 2 1 26 #&gt; 248 228 23.01.2017 14:53:46 3 5 4 26 #&gt; 249 256 25.01.2017 10:39:53 2 2 3 26 #&gt; 250 273 25.01.2017 17:11:34 3 4 3 26 #&gt; 251 9 07.01.2017 10:11:17 2 3 5 25 #&gt; 252 25 11.01.2017 20:30:43 2 1 1 25 #&gt; 253 32 12.01.2017 18:47:45 1 5 3 25 #&gt; 254 51 14.01.2017 13:55:30 2 5 2 25 #&gt; 255 69 15.01.2017 14:10:13 3 6 5 25 #&gt; 256 123 19.01.2017 12:36:03 1 3 4 25 #&gt; 257 161 20.01.2017 18:00:00 2 1 1 25 #&gt; 258 164 20.01.2017 18:17:03 3 4 2 25 #&gt; 259 209 22.01.2017 19:39:51 4 4 4 25 #&gt; 260 295 26.01.2017 16:18:27 1 3 1 25 #&gt; 261 302 27.01.2017 08:44:41 1 5 1 25 #&gt; 262 8 06.01.2017 17:24:53 2 5 3 24 #&gt; 263 16 09.01.2017 15:52:12 2 5 3 24 #&gt; 264 28 11.01.2017 22:44:23 2 6 2 24 #&gt; 265 30 12.01.2017 13:36:07 3 5 2 24 #&gt; 266 37 12.01.2017 19:20:25 3 3 4 24 #&gt; 267 67 15.01.2017 13:30:48 NA NA NA 24 #&gt; 268 92 17.01.2017 17:18:55 1 1 1 24 #&gt; 269 107 18.01.2017 16:01:36 3 2 1 24 #&gt; 270 130 19.01.2017 17:58:35 3 1 4 24 #&gt; 271 217 23.01.2017 11:18:51 2 6 3 24 #&gt; 272 232 23.01.2017 16:50:14 3 2 4 24 #&gt; 273 246 24.01.2017 15:09:44 NA NA NA 24 #&gt; 274 31 12.01.2017 14:09:10 4 8 5 23 #&gt; 275 45 13.01.2017 16:57:26 1 2 3 23 #&gt; 276 72 15.01.2017 15:30:15 4 4 4 23 #&gt; 277 86 16.01.2017 15:31:38 2 4 2 23 #&gt; 278 167 20.01.2017 19:17:44 4 5 4 23 #&gt; 279 195 22.01.2017 13:24:51 NA NA NA 23 #&gt; 280 221 23.01.2017 11:40:30 1 1 1 23 #&gt; 281 230 23.01.2017 16:27:49 1 1 1 23 #&gt; 282 283 26.01.2017 10:39:44 NA NA NA 23 #&gt; 283 13 09.01.2017 09:51:37 1 2 2 22 #&gt; 284 19 10.01.2017 17:16:48 NA NA NA 22 #&gt; 285 36 12.01.2017 19:09:14 1 7 3 22 #&gt; 286 55 14.01.2017 15:15:38 3 4 5 22 #&gt; 287 65 15.01.2017 12:41:27 3 6 6 22 #&gt; 288 220 23.01.2017 11:27:11 3 5 3 22 #&gt; 289 266 25.01.2017 15:39:13 2 4 4 22 #&gt; 290 269 25.01.2017 16:31:46 3 3 3 22 #&gt; 291 33 12.01.2017 18:53:43 1 3 2 21 #&gt; 292 102 18.01.2017 12:48:04 3 3 3 21 #&gt; 293 129 19.01.2017 17:58:02 2 4 3 21 #&gt; 294 186 21.01.2017 16:24:44 2 5 3 21 #&gt; 295 216 23.01.2017 07:54:17 4 2 5 21 #&gt; 296 223 23.01.2017 12:53:02 3 1 3 21 #&gt; 297 71 15.01.2017 15:03:29 3 3 3 20 #&gt; 298 97 17.01.2017 21:51:05 3 3 5 20 #&gt; 299 206 22.01.2017 18:42:49 NA NA NA 20 #&gt; 300 235 23.01.2017 18:26:20 NA NA NA 20 #&gt; 301 300 27.01.2017 02:14:27 2 3 2 20 #&gt; 302 35 12.01.2017 19:04:43 1 2 3 19 #&gt; 303 4 06.01.2017 09:58:05 2 3 2 18 #&gt; 304 131 19.01.2017 18:03:45 2 3 4 18 #&gt; 305 142 19.01.2017 19:02:12 3 4 1 18 #&gt; 306 234 23.01.2017 18:13:15 3 1 1 17 arrange(stats_test, interest, score) #&gt; X V_1 study_time self_eval interest score #&gt; 1 234 23.01.2017 18:13:15 3 1 1 17 #&gt; 2 142 19.01.2017 19:02:12 3 4 1 18 #&gt; 3 221 23.01.2017 11:40:30 1 1 1 23 #&gt; 4 230 23.01.2017 16:27:49 1 1 1 23 #&gt; 5 92 17.01.2017 17:18:55 1 1 1 24 #&gt; 6 107 18.01.2017 16:01:36 3 2 1 24 #&gt; 7 25 11.01.2017 20:30:43 2 1 1 25 #&gt; 8 161 20.01.2017 18:00:00 2 1 1 25 #&gt; 9 295 26.01.2017 16:18:27 1 3 1 25 #&gt; 10 302 27.01.2017 08:44:41 1 5 1 25 #&gt; 11 26 11.01.2017 20:38:16 1 3 1 26 #&gt; 12 151 20.01.2017 11:27:08 2 4 1 26 #&gt; 13 205 22.01.2017 18:29:17 2 2 1 26 #&gt; 14 66 15.01.2017 13:28:29 1 3 1 27 #&gt; 15 154 20.01.2017 13:38:19 4 5 1 27 #&gt; 16 224 23.01.2017 12:57:00 2 4 1 28 #&gt; 17 239 23.01.2017 20:00:46 3 4 1 28 #&gt; 18 261 25.01.2017 12:13:25 2 5 1 29 #&gt; 19 262 25.01.2017 12:49:57 1 2 1 29 #&gt; 20 276 25.01.2017 18:54:30 3 6 1 29 #&gt; 21 277 25.01.2017 20:06:34 3 4 1 29 #&gt; 22 121 19.01.2017 11:29:43 1 1 1 31 #&gt; 23 168 20.01.2017 20:04:38 1 1 1 32 #&gt; 24 297 26.01.2017 19:07:14 3 6 1 33 #&gt; 25 122 19.01.2017 11:30:57 2 2 1 34 #&gt; 26 75 15.01.2017 17:31:06 1 2 1 35 #&gt; 27 231 23.01.2017 16:32:32 1 1 1 35 #&gt; 28 169 20.01.2017 20:05:13 3 5 1 37 #&gt; 29 34 12.01.2017 18:57:47 4 7 1 38 #&gt; 30 179 21.01.2017 07:40:05 5 9 1 40 #&gt; 31 4 06.01.2017 09:58:05 2 3 2 18 #&gt; 32 300 27.01.2017 02:14:27 2 3 2 20 #&gt; 33 33 12.01.2017 18:53:43 1 3 2 21 #&gt; 34 13 09.01.2017 09:51:37 1 2 2 22 #&gt; 35 86 16.01.2017 15:31:38 2 4 2 23 #&gt; 36 28 11.01.2017 22:44:23 2 6 2 24 #&gt; 37 30 12.01.2017 13:36:07 3 5 2 24 #&gt; 38 51 14.01.2017 13:55:30 2 5 2 25 #&gt; 39 164 20.01.2017 18:17:03 3 4 2 25 #&gt; 40 20 10.01.2017 18:33:15 3 5 2 26 #&gt; 41 50 14.01.2017 10:53:38 1 3 2 26 #&gt; 42 54 14.01.2017 15:14:50 3 5 2 26 #&gt; 43 208 22.01.2017 18:58:58 1 2 2 27 #&gt; 44 243 24.01.2017 14:15:59 4 4 2 27 #&gt; 45 251 24.01.2017 20:02:38 1 1 2 27 #&gt; 46 70 15.01.2017 15:01:12 3 4 2 28 #&gt; 47 98 17.01.2017 21:59:36 2 2 2 28 #&gt; 48 147 19.01.2017 20:36:23 4 4 2 28 #&gt; 49 190 22.01.2017 11:19:10 3 6 2 28 #&gt; 50 215 22.01.2017 22:00:29 1 2 2 28 #&gt; 51 87 16.01.2017 16:51:20 3 7 2 29 #&gt; 52 127 19.01.2017 14:20:15 2 1 2 29 #&gt; 53 152 20.01.2017 13:02:50 2 4 2 29 #&gt; 54 44 13.01.2017 14:39:57 1 6 2 30 #&gt; 55 57 14.01.2017 15:39:12 2 6 2 30 #&gt; 56 101 18.01.2017 12:32:04 4 7 2 30 #&gt; 57 182 21.01.2017 11:29:16 3 2 2 30 #&gt; 58 192 22.01.2017 11:52:16 2 5 2 30 #&gt; 59 60 14.01.2017 17:14:18 2 7 2 31 #&gt; 60 204 22.01.2017 17:45:23 1 3 2 31 #&gt; 61 46 13.01.2017 18:34:25 3 7 2 32 #&gt; 62 52 14.01.2017 14:46:16 1 9 2 32 #&gt; 63 90 17.01.2017 14:34:13 3 7 2 32 #&gt; 64 304 27.01.2017 09:18:26 3 8 2 32 #&gt; 65 21 10.01.2017 21:17:52 4 7 2 33 #&gt; 66 68 15.01.2017 13:46:04 2 5 2 33 #&gt; 67 233 23.01.2017 17:03:10 2 9 2 33 #&gt; 68 143 19.01.2017 19:15:36 3 6 2 34 #&gt; 69 62 14.01.2017 17:52:29 2 8 2 35 #&gt; 70 93 17.01.2017 19:28:51 3 7 2 35 #&gt; 71 305 27.01.2017 09:52:59 3 8 2 35 #&gt; 72 146 19.01.2017 20:08:34 4 7 2 37 #&gt; 73 189 21.01.2017 20:05:54 4 6 2 37 #&gt; 74 299 26.01.2017 23:10:18 5 4 2 37 #&gt; 75 56 14.01.2017 15:27:10 3 8 2 39 #&gt; 76 58 14.01.2017 15:43:01 3 8 2 40 #&gt; 77 248 24.01.2017 16:29:45 2 10 2 40 #&gt; 78 35 12.01.2017 19:04:43 1 2 3 19 #&gt; 79 71 15.01.2017 15:03:29 3 3 3 20 #&gt; 80 102 18.01.2017 12:48:04 3 3 3 21 #&gt; 81 129 19.01.2017 17:58:02 2 4 3 21 #&gt; 82 186 21.01.2017 16:24:44 2 5 3 21 #&gt; 83 223 23.01.2017 12:53:02 3 1 3 21 #&gt; 84 36 12.01.2017 19:09:14 1 7 3 22 #&gt; 85 220 23.01.2017 11:27:11 3 5 3 22 #&gt; 86 269 25.01.2017 16:31:46 3 3 3 22 #&gt; 87 45 13.01.2017 16:57:26 1 2 3 23 #&gt; 88 8 06.01.2017 17:24:53 2 5 3 24 #&gt; 89 16 09.01.2017 15:52:12 2 5 3 24 #&gt; 90 217 23.01.2017 11:18:51 2 6 3 24 #&gt; 91 32 12.01.2017 18:47:45 1 5 3 25 #&gt; 92 53 14.01.2017 15:04:05 1 2 3 26 #&gt; 93 256 25.01.2017 10:39:53 2 2 3 26 #&gt; 94 273 25.01.2017 17:11:34 3 4 3 26 #&gt; 95 227 23.01.2017 14:30:40 3 8 3 27 #&gt; 96 236 23.01.2017 18:48:02 3 2 3 27 #&gt; 97 237 23.01.2017 19:07:33 3 2 3 27 #&gt; 98 24 11.01.2017 19:38:20 3 2 3 28 #&gt; 99 59 14.01.2017 16:26:40 2 6 3 28 #&gt; 100 61 14.01.2017 17:27:31 3 6 3 28 #&gt; 101 80 15.01.2017 20:39:10 3 6 3 28 #&gt; 102 145 19.01.2017 19:29:43 4 5 3 28 #&gt; 103 173 20.01.2017 21:13:25 2 3 3 28 #&gt; 104 210 22.01.2017 19:45:33 3 5 3 28 #&gt; 105 2 05.01.2017 21:07:56 3 7 3 29 #&gt; 106 176 20.01.2017 23:18:18 3 5 3 29 #&gt; 107 287 26.01.2017 11:56:19 4 8 3 29 #&gt; 108 23 11.01.2017 14:17:26 3 4 3 30 #&gt; 109 114 18.01.2017 22:20:33 1 4 3 30 #&gt; 110 198 22.01.2017 15:07:48 3 7 3 30 #&gt; 111 194 22.01.2017 12:27:59 4 6 3 31 #&gt; 112 250 24.01.2017 18:56:35 3 6 3 32 #&gt; 113 17 09.01.2017 20:49:48 2 5 3 33 #&gt; 114 63 15.01.2017 11:41:07 2 5 3 33 #&gt; 115 199 22.01.2017 15:26:55 3 5 3 33 #&gt; 116 254 25.01.2017 09:33:37 3 7 3 33 #&gt; 117 267 25.01.2017 16:08:48 3 6 3 33 #&gt; 118 94 17.01.2017 19:47:11 3 7 3 34 #&gt; 119 166 20.01.2017 19:03:10 4 6 3 34 #&gt; 120 170 20.01.2017 20:09:15 2 1 3 34 #&gt; 121 218 23.01.2017 11:21:21 3 5 3 34 #&gt; 122 240 24.01.2017 10:19:25 3 6 3 34 #&gt; 123 14 09.01.2017 12:15:48 4 9 3 35 #&gt; 124 38 13.01.2017 07:55:14 3 8 3 35 #&gt; 125 79 15.01.2017 19:54:00 3 4 3 35 #&gt; 126 148 19.01.2017 21:19:10 4 2 3 35 #&gt; 127 244 24.01.2017 14:38:56 3 5 3 35 #&gt; 128 128 19.01.2017 14:29:41 3 6 3 36 #&gt; 129 153 20.01.2017 13:03:25 3 7 3 37 #&gt; 130 252 25.01.2017 08:56:16 5 7 3 38 #&gt; 131 296 26.01.2017 17:12:37 3 6 3 38 #&gt; 132 298 26.01.2017 20:41:21 2 5 3 38 #&gt; 133 303 27.01.2017 08:50:31 5 8 3 38 #&gt; 134 39 13.01.2017 08:54:17 3 10 3 39 #&gt; 135 40 13.01.2017 09:31:06 4 9 3 39 #&gt; 136 64 15.01.2017 11:49:03 3 8 3 39 #&gt; 137 138 19.01.2017 18:23:23 3 9 3 39 #&gt; 138 144 19.01.2017 19:23:57 4 8 3 39 #&gt; 139 292 26.01.2017 15:00:29 4 8 3 39 #&gt; 140 29 12.01.2017 09:48:16 4 10 3 40 #&gt; 141 41 13.01.2017 12:07:29 4 10 3 40 #&gt; 142 257 25.01.2017 10:44:34 2 9 3 40 #&gt; 143 306 27.01.2017 11:29:48 4 9 3 40 #&gt; 144 131 19.01.2017 18:03:45 2 3 4 18 #&gt; 145 266 25.01.2017 15:39:13 2 4 4 22 #&gt; 146 72 15.01.2017 15:30:15 4 4 4 23 #&gt; 147 167 20.01.2017 19:17:44 4 5 4 23 #&gt; 148 37 12.01.2017 19:20:25 3 3 4 24 #&gt; 149 130 19.01.2017 17:58:35 3 1 4 24 #&gt; 150 232 23.01.2017 16:50:14 3 2 4 24 #&gt; 151 123 19.01.2017 12:36:03 1 3 4 25 #&gt; 152 209 22.01.2017 19:39:51 4 4 4 25 #&gt; 153 105 18.01.2017 15:46:15 3 6 4 26 #&gt; 154 120 19.01.2017 10:17:15 3 7 4 26 #&gt; 155 140 19.01.2017 18:37:53 3 7 4 26 #&gt; 156 228 23.01.2017 14:53:46 3 5 4 26 #&gt; 157 81 15.01.2017 20:59:54 3 3 4 27 #&gt; 158 200 22.01.2017 16:21:18 2 5 4 27 #&gt; 159 47 13.01.2017 20:52:32 1 4 4 29 #&gt; 160 73 15.01.2017 15:49:52 4 3 4 29 #&gt; 161 149 20.01.2017 09:02:45 3 5 4 30 #&gt; 162 12 08.01.2017 19:17:20 4 7 4 31 #&gt; 163 78 15.01.2017 18:31:00 3 6 4 31 #&gt; 164 193 22.01.2017 12:17:32 4 5 4 31 #&gt; 165 201 22.01.2017 17:03:55 3 6 4 31 #&gt; 166 229 23.01.2017 15:20:08 5 7 4 31 #&gt; 167 241 24.01.2017 10:28:57 3 4 4 31 #&gt; 168 260 25.01.2017 11:59:11 3 6 4 31 #&gt; 169 280 26.01.2017 03:01:08 4 7 4 31 #&gt; 170 11 08.01.2017 12:56:43 1 2 4 32 #&gt; 171 76 15.01.2017 18:00:15 3 7 4 32 #&gt; 172 100 18.01.2017 11:29:13 4 7 4 32 #&gt; 173 178 20.01.2017 23:54:46 3 6 4 32 #&gt; 174 184 21.01.2017 14:20:14 2 4 4 32 #&gt; 175 212 22.01.2017 21:34:56 4 5 4 32 #&gt; 176 88 16.01.2017 19:03:39 2 7 4 34 #&gt; 177 188 21.01.2017 19:01:18 4 8 4 36 #&gt; 178 279 25.01.2017 23:19:16 4 8 4 36 #&gt; 179 284 26.01.2017 10:46:10 4 5 4 36 #&gt; 180 126 19.01.2017 13:42:49 2 8 4 37 #&gt; 181 268 25.01.2017 16:15:57 4 7 4 38 #&gt; 182 281 26.01.2017 10:13:05 4 7 4 38 #&gt; 183 134 19.01.2017 18:22:43 1 4 4 39 #&gt; 184 135 19.01.2017 18:22:55 3 3 4 39 #&gt; 185 97 17.01.2017 21:51:05 3 3 5 20 #&gt; 186 216 23.01.2017 07:54:17 4 2 5 21 #&gt; 187 55 14.01.2017 15:15:38 3 4 5 22 #&gt; 188 31 12.01.2017 14:09:10 4 8 5 23 #&gt; 189 9 07.01.2017 10:11:17 2 3 5 25 #&gt; 190 69 15.01.2017 14:10:13 3 6 5 25 #&gt; 191 112 18.01.2017 19:41:09 3 5 5 26 #&gt; 192 95 17.01.2017 20:52:29 2 4 5 27 #&gt; 193 109 18.01.2017 17:47:57 2 4 5 27 #&gt; 194 203 22.01.2017 17:22:06 3 4 5 27 #&gt; 195 222 23.01.2017 12:06:58 3 6 5 27 #&gt; 196 82 15.01.2017 21:05:53 3 2 5 28 #&gt; 197 1 05.01.2017 13:57:01 5 8 5 29 #&gt; 198 282 26.01.2017 10:19:49 5 8 5 29 #&gt; 199 27 11.01.2017 20:49:19 2 4 5 30 #&gt; 200 48 13.01.2017 21:50:03 2 4 5 30 #&gt; 201 219 23.01.2017 11:24:30 2 7 5 30 #&gt; 202 263 25.01.2017 13:04:33 3 8 5 31 #&gt; 203 18 09.01.2017 22:57:38 3 3 5 32 #&gt; 204 77 15.01.2017 18:21:19 4 5 5 32 #&gt; 205 10 07.01.2017 18:10:05 4 5 5 33 #&gt; 206 156 20.01.2017 17:28:23 4 7 5 33 #&gt; 207 85 16.01.2017 13:56:29 3 6 5 34 #&gt; 208 115 18.01.2017 23:00:36 4 5 5 34 #&gt; 209 177 20.01.2017 23:37:45 4 7 5 34 #&gt; 210 259 25.01.2017 11:37:19 5 7 5 34 #&gt; 211 84 16.01.2017 13:51:51 4 8 5 35 #&gt; 212 103 18.01.2017 13:32:09 4 7 5 35 #&gt; 213 174 20.01.2017 22:58:35 5 8 5 35 #&gt; 214 165 20.01.2017 18:57:33 2 8 5 36 #&gt; 215 278 25.01.2017 21:08:40 5 6 5 36 #&gt; 216 96 17.01.2017 20:55:48 4 7 5 37 #&gt; 217 171 20.01.2017 20:29:52 4 9 5 37 #&gt; 218 22 11.01.2017 13:32:30 4 9 5 38 #&gt; 219 113 18.01.2017 21:44:02 5 8 5 38 #&gt; 220 181 21.01.2017 08:26:17 4 9 5 38 #&gt; 221 258 25.01.2017 11:25:38 5 9 5 38 #&gt; 222 108 18.01.2017 16:38:36 5 8 5 39 #&gt; 223 137 19.01.2017 18:22:58 4 10 5 39 #&gt; 224 264 25.01.2017 13:11:14 4 10 5 39 #&gt; 225 116 18.01.2017 23:07:32 4 8 5 40 #&gt; 226 175 20.01.2017 23:03:36 5 10 5 40 #&gt; 227 185 21.01.2017 15:01:26 4 10 5 40 #&gt; 228 196 22.01.2017 13:38:56 4 10 5 40 #&gt; 229 197 22.01.2017 14:55:17 4 10 5 40 #&gt; 230 65 15.01.2017 12:41:27 3 6 6 22 #&gt; 231 214 22.01.2017 21:57:36 2 6 6 31 #&gt; 232 301 27.01.2017 08:17:59 4 8 6 33 #&gt; 233 5 06.01.2017 14:13:08 4 8 6 34 #&gt; 234 172 20.01.2017 20:42:46 5 10 6 34 #&gt; 235 43 13.01.2017 14:14:16 4 8 6 36 #&gt; 236 110 18.01.2017 18:53:02 5 8 6 37 #&gt; 237 136 19.01.2017 18:22:57 3 1 6 39 #&gt; 238 3 05.01.2017 23:33:47 5 10 6 40 #&gt; 239 206 22.01.2017 18:42:49 NA NA NA 20 #&gt; 240 235 23.01.2017 18:26:20 NA NA NA 20 #&gt; 241 19 10.01.2017 17:16:48 NA NA NA 22 #&gt; 242 195 22.01.2017 13:24:51 NA NA NA 23 #&gt; 243 283 26.01.2017 10:39:44 NA NA NA 23 #&gt; 244 67 15.01.2017 13:30:48 NA NA NA 24 #&gt; 245 246 24.01.2017 15:09:44 NA NA NA 24 #&gt; 246 187 21.01.2017 16:27:32 NA NA NA 26 #&gt; 247 238 23.01.2017 19:53:10 NA NA NA 27 #&gt; 248 207 22.01.2017 18:56:56 NA NA NA 28 #&gt; 249 242 24.01.2017 14:09:33 NA NA NA 28 #&gt; 250 245 24.01.2017 14:56:24 NA NA NA 28 #&gt; 251 247 24.01.2017 15:37:27 NA NA NA 28 #&gt; 252 270 25.01.2017 16:35:41 NA NA NA 28 #&gt; 253 288 26.01.2017 13:36:14 NA NA NA 28 #&gt; 254 91 17.01.2017 15:19:36 NA NA NA 29 #&gt; 255 213 22.01.2017 21:47:06 NA NA NA 29 #&gt; 256 255 25.01.2017 10:05:00 NA NA NA 29 #&gt; 257 15 09.01.2017 15:23:15 NA NA NA 30 #&gt; 258 74 15.01.2017 16:12:54 NA NA NA 30 #&gt; 259 125 19.01.2017 13:03:26 NA NA NA 30 #&gt; 260 265 25.01.2017 13:14:00 NA NA NA 30 #&gt; 261 139 19.01.2017 18:35:56 NA NA NA 31 #&gt; 262 157 20.01.2017 17:34:48 NA NA NA 31 #&gt; 263 183 21.01.2017 12:20:37 NA NA NA 31 #&gt; 264 289 26.01.2017 14:19:14 NA NA NA 31 #&gt; 265 124 19.01.2017 12:51:10 NA NA NA 32 #&gt; 266 150 20.01.2017 09:53:47 NA NA NA 32 #&gt; 267 118 19.01.2017 08:54:43 NA NA NA 33 #&gt; 268 89 16.01.2017 21:18:05 NA NA NA 34 #&gt; 269 141 19.01.2017 18:44:32 NA NA NA 34 #&gt; 270 159 20.01.2017 17:57:26 NA NA NA 34 #&gt; 271 160 20.01.2017 17:59:19 NA NA NA 34 #&gt; 272 271 25.01.2017 16:53:17 NA NA NA 34 #&gt; 273 275 25.01.2017 18:06:36 NA NA NA 34 #&gt; 274 285 26.01.2017 10:54:41 NA NA NA 34 #&gt; 275 294 26.01.2017 15:51:56 NA NA NA 34 #&gt; 276 162 20.01.2017 18:00:53 NA NA NA 35 #&gt; 277 158 20.01.2017 17:53:16 NA NA NA 36 #&gt; 278 163 20.01.2017 18:04:21 NA NA NA 36 #&gt; 279 191 22.01.2017 11:31:27 NA NA NA 36 #&gt; 280 202 22.01.2017 17:13:02 NA NA NA 36 #&gt; 281 226 23.01.2017 14:17:10 NA NA NA 36 #&gt; 282 272 25.01.2017 17:03:21 NA NA NA 36 #&gt; 283 290 26.01.2017 14:34:23 NA NA NA 36 #&gt; 284 293 26.01.2017 15:17:47 NA NA NA 36 #&gt; 285 99 18.01.2017 09:04:30 NA NA NA 37 #&gt; 286 111 18.01.2017 19:24:49 NA NA NA 37 #&gt; 287 117 19.01.2017 08:06:05 NA NA NA 37 #&gt; 288 274 25.01.2017 17:38:36 NA NA NA 37 #&gt; 289 42 13.01.2017 14:08:08 NA NA NA 38 #&gt; 290 106 18.01.2017 15:52:04 NA NA NA 38 #&gt; 291 133 19.01.2017 18:22:38 NA NA NA 38 #&gt; 292 211 22.01.2017 20:28:43 NA NA NA 38 #&gt; 293 286 26.01.2017 11:19:10 NA NA NA 38 #&gt; 294 6 06.01.2017 14:21:18 NA NA NA 39 #&gt; 295 49 14.01.2017 07:02:39 NA NA NA 39 #&gt; 296 104 18.01.2017 13:42:20 NA NA NA 39 #&gt; 297 155 20.01.2017 15:33:55 NA NA NA 39 #&gt; 298 180 21.01.2017 08:04:17 NA NA NA 39 #&gt; 299 225 23.01.2017 13:24:22 NA NA NA 39 #&gt; 300 253 25.01.2017 09:32:55 NA NA NA 39 #&gt; 301 291 26.01.2017 14:55:17 NA NA NA 39 #&gt; 302 7 06.01.2017 14:25:49 NA NA NA 40 #&gt; 303 83 16.01.2017 10:16:52 NA NA NA 40 #&gt; 304 119 19.01.2017 09:05:01 NA NA NA 40 #&gt; 305 132 19.01.2017 18:22:32 NA NA NA 40 #&gt; 306 249 24.01.2017 17:19:54 NA NA NA 40 Einige Anmerkungen. Die generelle Syntax lautet arrange(df, Spalte1, ...), wobei df den Dataframe bezeichnet und Spalte1 die erste zu sortierende Spalte; die Punkte ... geben an, dass man weitere Parameter übergeben kann. Am wichtigsten ist hier, dass man weitere Spalten übergeben kann. Dazu gleich mehr. Standardmäßig sortiert arrange aufsteigend (weil kleine Zahlen im Zahlenstrahl vor den großen Zahlen kommen). Möchte man diese Reihenfolge umdrehen (große Werte zuert), so kann man ein Minuszeichen vor den Namen der Spalte setzen. Gibt man zwei oder mehr Spalten an, so werden pro Wert von Spalte1 die Werte von Spalte2 sortiert etc; man betrachte den Output des Beispiels oben dazu. Merke: Die Funktion arrange sortiert die Zeilen eines Datafames. Ein Sinnbild zur Verdeutlichung: knitr::include_graphics(&quot;./images/arrange.pdf&quot;) Ein ähnliches Ergebnis erhält mit man top_n(), welches die n kleinsten Ränge widergibt: top_n(stats_test, 3) #&gt; Selecting by score #&gt; X V_1 study_time self_eval interest score #&gt; 1 3 05.01.2017 23:33:47 5 10 6 40 #&gt; 2 7 06.01.2017 14:25:49 NA NA NA 40 #&gt; 3 29 12.01.2017 09:48:16 4 10 3 40 #&gt; 4 41 13.01.2017 12:07:29 4 10 3 40 #&gt; 5 58 14.01.2017 15:43:01 3 8 2 40 #&gt; 6 83 16.01.2017 10:16:52 NA NA NA 40 #&gt; 7 116 18.01.2017 23:07:32 4 8 5 40 #&gt; 8 119 19.01.2017 09:05:01 NA NA NA 40 #&gt; 9 132 19.01.2017 18:22:32 NA NA NA 40 #&gt; 10 175 20.01.2017 23:03:36 5 10 5 40 #&gt; 11 179 21.01.2017 07:40:05 5 9 1 40 #&gt; 12 185 21.01.2017 15:01:26 4 10 5 40 #&gt; 13 196 22.01.2017 13:38:56 4 10 5 40 #&gt; 14 197 22.01.2017 14:55:17 4 10 5 40 #&gt; 15 248 24.01.2017 16:29:45 2 10 2 40 #&gt; 16 249 24.01.2017 17:19:54 NA NA NA 40 #&gt; 17 257 25.01.2017 10:44:34 2 9 3 40 #&gt; 18 306 27.01.2017 11:29:48 4 9 3 40 top_n(stats_test, 3, interest) #&gt; X V_1 study_time self_eval interest score #&gt; 1 3 05.01.2017 23:33:47 5 10 6 40 #&gt; 2 5 06.01.2017 14:13:08 4 8 6 34 #&gt; 3 43 13.01.2017 14:14:16 4 8 6 36 #&gt; 4 65 15.01.2017 12:41:27 3 6 6 22 #&gt; 5 110 18.01.2017 18:53:02 5 8 6 37 #&gt; 6 136 19.01.2017 18:22:57 3 1 6 39 #&gt; 7 172 20.01.2017 20:42:46 5 10 6 34 #&gt; 8 214 22.01.2017 21:57:36 2 6 6 31 #&gt; 9 301 27.01.2017 08:17:59 4 8 6 33 Gibt man keine Spalte an, so bezieht sich top_n auf die letzte Spalte im Datensatz. 6.2.3.4 Datensatz gruppieren mit group_by Einen Datensatz zu gruppieren ist ebenfalls eine häufige Angelegenheit: Was ist der mittlere Umsatz in Region X im Vergleich zu Region Y? Ist die Reaktionszeit in der Experimentalgruppe kleiner als in der Kontrollgruppe? Können Männer schneller ausparken als Frauen? Man sieht, dass das Gruppieren v.a. in Verbindung mit Mittelwerten oder anderen Zusammenfassungen sinnvol ist; dazu im nächsten Abschnitt mehr. knitr::include_graphics(&quot;./images/group_by.pdf&quot;) In der Abbildung wurde der Datensatz anhand der Spalte Fach in mehrere Gruppen geteilt. Wir könnten uns als nächstes z.B. Mittelwerte pro Fach - d.h. pro Gruppe (pro Ausprägung von Fach) - ausgeben lassen; in diesem Fall vier Gruppen (Fach A bis D). test_gruppiert &lt;- group_by(stats_test, interest) test_gruppiert #&gt; Source: local data frame [306 x 6] #&gt; Groups: interest [7] #&gt; #&gt; X V_1 study_time self_eval interest score #&gt; &lt;int&gt; &lt;fctr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 05.01.2017 13:57:01 5 8 5 29 #&gt; 2 2 05.01.2017 21:07:56 3 7 3 29 #&gt; 3 3 05.01.2017 23:33:47 5 10 6 40 #&gt; 4 4 06.01.2017 09:58:05 2 3 2 18 #&gt; 5 5 06.01.2017 14:13:08 4 8 6 34 #&gt; 6 6 06.01.2017 14:21:18 NA NA NA 39 #&gt; # ... with 300 more rows Schaut man sich nun den Datensatz an, sieht man erstmal wenig Effekt der Gruppierung. R teilt uns lediglich mit Groups: interest [7], dass es die Gruppen gibt, aber es gibt keine extra Spalte oder sonstige Anzeichen der Gruppierung. Aber keine Sorge, wenn wir gleich einen Mittelwert ausrechnen, bekommen wir den Mittelwert pro Gruppe! Merke: &gt; Mit group_by teilt man einen Datensatz in Gruppen ein, entsprechend der Werte einer mehrerer Spalten. Literaturverzeichnis "]
]
